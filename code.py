# -*- coding: utf-8 -*-
"""Untitled85.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/170uDgaj1NxT1iA1KzcTbN7Sqfe5CSGXq
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

"""**Above is the details of customers of bank with name xyz. the xyz bank have launched a new service in the bank (eg. edu.loan, buisness loan, home loan etc) AIm: build a classification model that can predict whether the customer will choose the service or not**"""

df=pd.read_csv("/content/bank-additional-full_final (1).csv",sep=";")

df

df.info()

"""**EDA---> Exploratory data analysis**"""

df.isnull().sum()

df.dropna(inplace=True)

df.isnull().sum()

df.isnull().sum()

df.duplicated().sum()

df.drop_duplicates(inplace=True)

df.duplicated().sum()

df.columns

"""Outliers analysis done by **boxplot** **bold text**"""

for col in df.columns:
  if df[col].dtype!="object":
     plt.boxplot(df[col])
     plt.title(col)
     plt.show()

out_cols=['age', 'duration', 'campaign','cons.conf.idx']

for col in out_cols:
    Q1=df[col].quantile(0.25)
    Q3=df[col].quantile(0.75)
    IQR=Q3-Q1
    LL=Q1-1.5*IQR
    UL=Q3+1.5*IQR
    df=df[(df[col]>=LL)&(df[col]<=UL)]

df

for col in df.columns:
  if df[col].dtype!="object":
     plt.boxplot(df[col])
     plt.title(col)
     plt.show()

df.columns

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()

for col in df.columns:
  if df[col].dtype=="object":
    df[col]=le.fit_transform(df[col])

df

df.info()

"""**Feature selection:------**"""

df.corr()

plt.figure(figsize=(20,10))
sns.heatmap(df.corr(),cmap="Greens",annot=True)

# VIF--> Checking for multi-collinearity.

from statsmodels.stats.outliers_influence import variance_inflation_factor

cols=[]

for i in df.columns:
  if i!="y":
    cols.append(i)

cols

x=df[cols]
x

vif_data=pd.DataFrame()
vif_data["features"]=x.columns
vif_data["multicollinearity"]=[variance_inflation_factor(x.values,i) for i in range(len(x.columns))]

vif_data

x.drop(["nr.employed"],axis=1,inplace=True)

x

vif_data=pd.DataFrame()
vif_data["features"]=x.columns
vif_data["multicollinearity"]=[variance_inflation_factor(x.values,i) for i in range(len(x.columns))]

vif_data

x.drop(["cons.price.idx"],axis=1,inplace=True)

vif_data=pd.DataFrame()
vif_data["features"]=x.columns
vif_data["multicollinearity"]=[variance_inflation_factor(x.values,i) for i in range(len(x.columns))]
vif_data

x.drop(["pdays"],axis=1,inplace=True)

vif_data=pd.DataFrame()
vif_data["features"]=x.columns
vif_data["multicollinearity"]=[variance_inflation_factor(x.values,i) for i in range(len(x.columns))]
vif_data

x.drop(["euribor3m"],axis=1,inplace=True)

vif_data=pd.DataFrame()
vif_data["features"]=x.columns
vif_data["multicollinearity"]=[variance_inflation_factor(x.values,i) for i in range(len(x.columns))]
vif_data

x.drop(["cons.conf.idx"],axis=1,inplace=True)

vif_data=pd.DataFrame()
vif_data["features"]=x.columns
vif_data["multicollinearity"]=[variance_inflation_factor(x.values,i) for i in range(len(x.columns))]
vif_data

x.drop(["age"],axis=1,inplace=True)

vif_data=pd.DataFrame()
vif_data["features"]=x.columns
vif_data["multicollinearity"]=[variance_inflation_factor(x.values,i) for i in range(len(x.columns))]
vif_data

x.drop(["poutcome"],axis=1,inplace=True)

vif_data=pd.DataFrame()
vif_data["features"]=x.columns
vif_data["multicollinearity"]=[variance_inflation_factor(x.values,i) for i in range(len(x.columns))]
vif_data

x

y=df["y"]
y

"""**Model building part**"""

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=45)

lg_model=LogisticRegression()
lg_model

lg_model.fit(x_train,y_train)

lg_pred=lg_model.predict(x_test)

y_test

x_test

from sklearn.metrics import *

accuracy_score(y_test,lg_pred)

cm=confusion_matrix(y_test,lg_pred)
cm

sns.heatmap(cm,cmap="Greens",annot=True,fmt="d")

Hence we have built a model with 92 % accuracy.